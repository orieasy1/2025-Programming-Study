from fastapi import FastAPI
from fastapi.responses import StreamingResponse, HTMLResponse
import cv2
import threading
import time
import os
import numpy as np
from collections import deque

app = FastAPI()

# ì›¹ìº  ì—°ê²°
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

# ë…¹í™” ì„¤ì •
video_writer = None
frame_rate = 30
is_recording = False
last_frame = None
lock = threading.Lock()

# ì´ë²¤íŠ¸ ê°ì§€ìš©
pre_event_frames = deque(maxlen=frame_rate * 10)
post_event_frames = frame_rate * 3

# íˆíŠ¸ë§µ ê´€ë ¨
motion_heatmap = None
heatmap_threshold = 255 * 1000
decay_rate = 0.9

# ëª¨ì…˜ ê°ì§€ ìƒíƒœ ë³€ìˆ˜
motion_duration_counter = 0
motion_trigger_min_duration = frame_rate * 2
motion_start_time = None
record_ready = False
post_record_counter = 0

# ì €ì¥ ë””ë ‰í† ë¦¬
SAVE_DIR = "recorded_videos"
os.makedirs(SAVE_DIR, exist_ok=True)


def detect_changes(frame):
    global last_frame, motion_heatmap

    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)

    if last_frame is None:
        last_frame = gray_frame
        motion_heatmap = np.zeros_like(gray_frame, dtype=np.float32)
        return False

    frame_diff = cv2.absdiff(last_frame, gray_frame)
    _, threshold_diff = cv2.threshold(frame_diff, 25, 255, cv2.THRESH_BINARY)

    last_frame = gray_frame

    motion_heatmap[:] = motion_heatmap * decay_rate + threshold_diff.astype(np.float32)
    heat_score = np.sum(motion_heatmap)

    return heat_score > heatmap_threshold


def start_recording():
    global video_writer, is_recording, motion_start_time
    filename = os.path.join(SAVE_DIR, f"event_{time.strftime('%Y%m%d_%H%M%S')}.mp4")
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')

    if pre_event_frames:
        height, width, _ = pre_event_frames[0][1].shape
    else:
        ret, frame = cap.read()
        if not ret:
            return
        height, width, _ = frame.shape

    with lock:
        video_writer = cv2.VideoWriter(filename, fourcc, frame_rate, (width, height))
        is_recording = True
        print(f"[REC] ì‹œì‘: {filename}")

        from_ts = motion_start_time - 3
        to_ts = motion_start_time + 2

        for ts, frame in pre_event_frames:
            if from_ts <= ts <= to_ts:
                video_writer.write(frame)


def stop_recording():
    global video_writer, is_recording
    with lock:
        if video_writer:
            video_writer.release()
            video_writer = None
            is_recording = False
            print("[REC] ì¢…ë£Œ")


# ğŸ¥ ëª¨ì…˜ ê°ì§€ ë° ë…¹í™”ëŠ” ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
def motion_detection_thread():
    global is_recording, motion_duration_counter, record_ready, motion_start_time, post_record_counter

    while True:
        ret, frame = cap.read()
        if not ret:
            continue

        now = time.time()
        pre_event_frames.append((now, frame.copy()))

        change_detected = detect_changes(frame)

        if change_detected:
            if motion_duration_counter == 0:
                motion_start_time = now
            motion_duration_counter += 1
            post_record_counter = 0

            if not is_recording and motion_duration_counter >= motion_trigger_min_duration:
                record_ready = True

            if record_ready:
                start_recording()
                record_ready = False

            if is_recording:
                with lock:
                    video_writer.write(frame)

        else:
            if not is_recording:
                motion_duration_counter = 0
                record_ready = False

            if is_recording:
                if post_record_counter < post_event_frames:
                    with lock:
                        video_writer.write(frame)
                    post_record_counter += 1
                else:
                    stop_recording()
                    post_record_counter = 0

        time.sleep(1 / frame_rate)


# ğŸ“¡ ìŠ¤íŠ¸ë¦¬ë° ì „ìš© (ëª¨ì…˜ ê°ì§€ëŠ” ì•ˆí•¨)
def generate_frames():
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        heatmap_display = cv2.convertScaleAbs(motion_heatmap)
        colored_heatmap = cv2.applyColorMap(heatmap_display, cv2.COLORMAP_JET)
        combined = cv2.hconcat([frame, colored_heatmap])

        _, buffer = cv2.imencode('.jpg', combined)
        frame_bytes = buffer.tobytes()

        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n\r\n')


# ìŠ¤íŠ¸ë¦¬ë° API
@app.get("/video")
async def video():
    return StreamingResponse(generate_frames(), media_type="multipart/x-mixed-replace; boundary=frame")


# HTML í˜ì´ì§€ API
@app.get("/")
async def get():
    html_content = """
    <html>
        <head>
            <title>Live Stream with Heatmap</title>
        </head>
        <body>
            <h1>Live Stream + Heatmap</h1>
            <img src="/video" width="800">
        </body>
    </html>
    """
    return HTMLResponse(content=html_content)


# ì•± ì‹œì‘ ì‹œ ëª¨ì…˜ ê°ì§€ ìŠ¤ë ˆë“œ ì‹œì‘
@app.on_event("startup")
def start_motion_detection_thread():
    print("ğŸ”„ ë°±ê·¸ë¼ìš´ë“œ ëª¨ì…˜ ê°ì§€ ìŠ¤ë ˆë“œ ì‹¤í–‰ ì¤‘...")
    threading.Thread(target=motion_detection_thread, daemon=True).start()
